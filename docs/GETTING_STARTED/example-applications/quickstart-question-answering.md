---
title: "Question answering (using USE QA Tensorflow Hub)"
slug: "quickstart-question-answering"
excerpt: "Get started with Relevance AI in 5 minutes!"
hidden: false
createdAt: "2021-11-05T06:25:12.543Z"
updatedAt: "2022-01-20T05:05:33.448Z"
---
This quickstart shows how easy it is to get started and how to quickly build question-answering applications using Relevance AI in just a few lines of code. Visit the documentation pages on use-cases for more in-depth tutorials and explanations for experimenting with stronger vector search.

<figure>
<img src="https://github.com/RelevanceAI/RelevanceAI-readme-docs/blob/v0.33.2/docs_template/_assets/RelevanceAI_questin_answering.png?raw=true" width="650" alt="Vector Spaces" />
<figcaption></figcaption>
<figure>

For each application, we demonstrate the ease of 
* encoding data, 
* indexing the data
* vector search 

to build powerful applications

**Try it out in Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zL2mwBVCPaccjB7o7XoVJVJKOWRom8mq?usp=sharing)

### What I Need
* Project and API Key: Grab your RelevanceAI project and API key by [signing up](https://cloud.relevance.ai/ )
* Python 3 (ideally a Jupyter Notebook/Colab environment)

### Installation Requirements

Prior to starting, we need to install the main dependencies.
```bash Bash
!pip install -U RelevanceAI[notebook]==0.33.2

!pip install -q vectorhub[encoders-text-tfhub]
```
```bash
```
### Setting Up Client

To be able to use Relevance AI, you need to instantiate a client. This needs a Project and API key that can be accessed at https://cloud.relevance.ai/ in the settings area! Alternatively, you can run the code below and follow the link and the guide.

```python Python (SDK)
from relevanceai import Client

"""
You can sign up/login and find your credentials here: https://cloud.relevance.ai/sdk/api
Once you have signed up, click on the value under `Authorization token` and paste it here
"""
client = Client()

```
```python
```


For this guide, we use our sample ecommerce dataset as shown below:
```python Python (SDK)
import pandas as pd
from relevanceai.datasets import get_ecommerce_dataset_clean

# Retrieve our sample dataset. - This comes in the form of a list of documents.
documents = get_ecommerce_dataset_clean()

pd.DataFrame.from_dict(documents).head()
```
```python
```

## Question Answering (Using TFHub's Universal Sentence Encoder QA) 

Question answering can be a useful application of vector databases particularly for customer support and supporting search for FAQ documents. Here, we show an example of using TFHub's Question Answering Model.

### Data prepration
First, we will define our encoder functions:

```python Python (SDK)
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import tensorflow_text

# Here we load the model and define how we encode
module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')

# First we define how we encode the queries
def encode_query(query: str):
    return module.signatures['question_encoder'](tf.constant([query]))['outputs'][0].numpy().tolist()

# We then want to define how we encode the answers
def encode_answer(answer: str):
    return module.signatures['response_encoder'](
        input=tf.constant([answer]), 
        context=tf.constant([answer]))['outputs'][0].numpy().tolist()

```
```python
```


Next, we will encode the `product_title` field within our documents:

```python Python (SDK)
from tqdm.auto import tqdm

for d in tqdm(documents):
    d['product_title_use_qa_vector_'] = encode_answer(d['product_title'])

```
```python
```


Finally, we can upload the results to a dataset called `quickstart_tfhub_qa` in the Relevance AI platform:

```python Python (SDK)
DATASET_ID = "quickstart_tfhub_qa"
df = client.Dataset(DATASET_ID)
df.delete()
df.insert_documents(documents)
```
```python
```


### Search
To be able to search within vectors that are generated by the Universal Sentence Encoder, we need to encode the query with the same vectorizer and then form a vector search as shown below:

```python Python (SDK)
query = "for my baby daughter"
query_vector = encode_query(query)

```
```python
```

Forming a multi-vector query and hitting the vector search endpoint:

```python Python (SDK)

multivector_query=[
        {
            "vector": query_vector,
            "fields": ["product_title_use_qa_vector_"]}
    ]

```
```python
```

```python Python (SDK)
#Perform a vector search
results = df.vector_search(
    multivector_query=multivector_query,
    page_size=5
)
```
```python
```

```python Python (SDK)

from relevanceai import show_json
show_json(
    results['results'],
    text_fields=["product_title"],
)

```
```python
```

<figure>
<img src="https://github.com/RelevanceAI/RelevanceAI-readme-docs/blob/v0.33.2/docs_template/GETTING_STARTED/example-applications/_assets/RelevanceAI_questin_answering_res.png?raw=true" width="650" alt="Vector Spaces" />
<figcaption></figcaption>
<figure>

## Final Code

```python Python (SDK)

from relevanceai import Client 

client = Client()

import pandas as pd
from relevanceai.datasets import get_ecommerce_dataset_clean

# Retrieve our sample dataset. - This comes in the form of a list of documents.
documents = get_ecommerce_dataset_clean()

pd.DataFrame.from_dict(documents).head()

# encoding
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import tensorflow_text

# Here we load the model and define how we encode
module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')

# First we define how we encode the queries
def encode_query(query: str):
    return module.signatures['question_encoder'](tf.constant([query]))['outputs'][0].numpy().tolist()

# We then want to define how we encode the answers
def encode_answer(answer: str):
    return module.signatures['response_encoder'](
        input=tf.constant([answer]), 
        context=tf.constant([answer]))['outputs'][0].numpy().tolist()

# Endoing the dataset
from tqdm.auto import tqdm

for d in tqdm(documents):
    d['product_title_use_qa_vector_'] = encode_answer(d['product_title'])

import uuid

for d in documents:
  d['_id'] = uuid.uuid4().__str__()    # Each document must have a field '_id'

# Insert the documents into a dataset called quickstart_tfhub_qa.
dataset_id = "quickstart_tfhub_qa"
df = client.Dataset(dataset_id)
df.delete()
df.insert_documents(documents)

# Vector search 
query = "for my baby daughter"
query_vector = encode_query(query)

results = df.vector_search(
    multivector_query=[
        {
            "vector": query_vector,
            "fields": ["product_title_use_qa_vector_"]}
    ],
    page_size=5
)

# Showing results using json_shower
from relevanceai import show_json
show_json(
    results['results'],
    text_fields=["product_title"],
    image_fields = ["product_image"]
)

```
```python
```
