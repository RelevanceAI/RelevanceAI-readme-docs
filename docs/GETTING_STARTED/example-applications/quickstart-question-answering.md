---
title: "Question answering (using USE QA Tensorflow Hub)"
slug: "quickstart-question-answering"
excerpt: "Get started with Relevance AI in 5 minutes!"
hidden: false
createdAt: "2021-11-05T06:25:12.543Z"
updatedAt: "2022-01-20T05:05:33.448Z"
---
This quickstart shows how easy it is to get started and how to quickly build question-answering applications using Relevance AI in just a few lines of code. Visit the documentation pages on use-cases for more in-depth tutorials and explanations for experimenting with stronger vector search.

<figure>
<img src="https://github.com/RelevanceAI/RelevanceAI-readme-docs/blob/v1.2.7/docs_template/GETTING_STARTED/example-applications/_assets/RelevanceAI_question_answering.png?raw=true" width="650" alt="Vector Spaces" />
<figcaption></figcaption>

<figure>

For each application, we demonstrate the ease of
* encoding data,
* indexing the data
* vector search

to build powerful applications

**Try it out in Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/RelevanceAI-readme-docs/blob/v1.2.7/docs/GETTING_STARTED/example-applications/_notebooks/RelevanceAI-ReadMe-Question-Answering-using-USE-QA-Tensorflow-Hub.ipynb)

### What I Need
* Project and API Key: Grab your RelevanceAI project and API key by [signing up](https://cloud.relevance.ai/ )
* Python 3 (ideally a Jupyter Notebook/Colab environment)

### Installation Requirements

Prior to starting, we need to install the main dependencies.
```bash Bash
# remove `!` if running the line in a terminal
!pip install -U RelevanceAI[notebook]==1.2.7

# remove `!` if running the line in a terminal
!pip install vectorhub[encoders-text-tfhub]
```
```bash
```

### Setting Up Client
To be able to use Relevance AI, you need to instantiate a client. This needs a Project and API key that can be accessed at https://cloud.relevance.ai/ in the settings area! Alternatively, you can run the code below and follow the link and the guide.

```python Python (SDK)
from relevanceai import Client

"""
You can sign up/login and find your credentials here: https://cloud.relevance.ai/sdk/api
Once you have signed up, click on the value under `Activation token` and paste it here
"""
client = Client()
```
```python
```


For this guide, we use our sample ecommerce dataset as shown below:


```python Python (SDK)
import pandas as pd
from relevanceai.datasets import get_ecommerce_dataset_clean

# Retrieve our sample dataset. - This comes in the form of a list of documents.
documents = get_ecommerce_dataset_clean()

pd.DataFrame.from_dict(documents).head()
```
```python
```

## Question Answering (Using TFHub's Universal Sentence Encoder QA)

Question answering can be a useful application of vector databases particularly for customer support and supporting search for FAQ documents. Here, we show an example of using TFHub's Question Answering Model.

### Data Preparation
First, we will define our encoder functions:

```python Python (SDK)
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import tensorflow_text

# Here we load the model and define how we encode
module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')

# First we define how we encode the queries
def encode_query(query: str):
    return module.signatures['question_encoder'](tf.constant([query]))['outputs'][0].numpy().tolist()

# We then want to define how we encode the answers
def encode_answer(answer: str):
    return module.signatures['response_encoder'](
        input=tf.constant([answer]),
        context=tf.constant([answer]))['outputs'][0].numpy().tolist()
```
```python
```

Next, we will encode the `product_title` field within our documents:


```python Python (SDK)
from tqdm.auto import tqdm

for d in tqdm(documents):
    d['product_title_use_qa_vector_'] = encode_answer(d['product_title'])
```
```python
```

Finally, we can upload the results to a dataset called `quickstart_tfhub_qa` in the Relevance AI platform:

```python Python (SDK)
df = client.Dataset("quickstart_tfhub_qa")
df.insert_documents(documents)
```
```python
```


### Search
To be able to search within vectors that are generated by the Universal Sentence Encoder, we need to encode the query with the same vectorizer and then form a vector search as shown below:


```python Python (SDK)
query = 'What is a good mothers day gift?'
query_vector = encode_query(query)
```
```python
```


Forming a multi-vector query and hitting the vector search endpoint:


```python Python (SDK)
multivector_query=[
        { "vector": query_vector, "fields": ["product_title_use_qa_vector_"]}
    ]

results = df.vector_search(
    multivector_query=multivector_query,
    page_size=5
)
```
```python
```


```python Python (SDK)
from relevanceai import show_json

print('=== QUERY === ')
print(query)

print('=== RESULTS ===')
show_json(results, image_fields=["product_image"], text_fields=["product_title"])
```
```python
```



<figure>
<img src="https://github.com/RelevanceAI/RelevanceAI-readme-docs/blob/v1.2.7/docs_template/GETTING_STARTED/example-applications/_assets/RelevanceAI_question_answering_search_results.png?raw=true" width="650" alt="Question Answering Search Results" />
<figcaption>Question Answering Search Results</figcaption>
<figure>

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/RelevanceAI-readme-docs/blob/v1.2.7/docs/GETTING_STARTED/example-applications/_notebooks/RelevanceAI-ReadMe-Question-Answering-using-USE-QA-Tensorflow-Hub.ipynb)

## Final Code


```python Python (SDK)
from relevanceai import Client

"""
You can sign up/login and find your credentials here: https://cloud.relevance.ai/sdk/api
Once you have signed up, click on the value under `Activation token` and paste it here
"""
client = Client()

import pandas as pd
from relevanceai.datasets import get_ecommerce_dataset_clean

# Retrieve our sample dataset. - This comes in the form of a list of documents.
documents = get_ecommerce_dataset_clean()

pd.DataFrame.from_dict(documents).head()

import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import tensorflow_text

# Here we load the model and define how we encode
module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')

# First we define how we encode the queries
def encode_query(query: str):
    return module.signatures['question_encoder'](tf.constant([query]))['outputs'][0].numpy().tolist()

# We then want to define how we encode the answers
def encode_answer(answer: str):
    return module.signatures['response_encoder'](
        input=tf.constant([answer]),
        context=tf.constant([answer]))['outputs'][0].numpy().tolist()

from tqdm.auto import tqdm

for d in tqdm(documents):
    d['product_title_use_qa_vector_'] = encode_answer(d['product_title'])

df = client.Dataset("quickstart_tfhub_qa")
df.insert_documents(documents)

query = 'What is an expensive gift?'
query_vector = encode_query(query)

multivector_query=[
        { "vector": query_vector, "fields": ["product_title_use_qa_vector_"]}
    ]

results = df.vector_search(
    multivector_query=multivector_query,
    page_size=5
)

from relevanceai import show_json

print('=== QUERY === ')
print(query)

print('=== RESULTS ===')
show_json(results, image_fields=["product_image"], text_fields=["product_title"])
```
```python
```

