{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "2fchptpo9hl9"
            },
            "source": [
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/RelevanceAI-readme-docs/blob/v1.4.5/docs/general-features/how-to-vectorize/_notebooks/RelevanceAI_ReadMe_How_to_Vectorize.ipynb)",
                "\n",
                "# Installation\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "dPn23fZQjjmO"
            },
            "outputs": [],
            "source": [
                "# remove `!` if running the line in a terminal\n!pip install -U RelevanceAI[notebook]==1.4.5\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "XtAf7b1BjjmP"
            },
            "outputs": [],
            "source": [
                "from relevanceai import Client\n\n\"\"\"\nYou can sign up/login and find your credentials here: https://cloud.relevance.ai/sdk/api\nOnce you have signed up, click on the value under `Activation token` and paste it here\n\"\"\"\nclient = Client()\n\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "mjnTgYLNjjmP"
            },
            "source": [
                "## Vectorizing using Vectorhub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "YYVL1Lg39EVu"
            },
            "outputs": [],
            "source": [
                "## Installing Vectorhub with access to Tfhub models!\n",
                "# remove `!` if running the line in a terminal\n!pip install vectorhub[encoders-text-tfhub]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Deqi6bojjjmQ"
            },
            "outputs": [],
            "source": [
                "## Installing Vectorhub with access to Sentence Transformer models\n",
                "# remove `!` if running the line in a terminal\n!pip install vectorhub[sentence-transformers]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "HbjB7y4JjjmQ"
            },
            "outputs": [],
            "source": [
                "## Installing Vectorhub with access to Huggingface models\n",
                "# remove `!` if running the line in a terminal\n!pip install vectorhub[transformers]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "k1yHM-mnjGcQ"
            },
            "source": [
                "# Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cDJ34fhYjD24"
            },
            "outputs": [],
            "source": [
                "## Let's use a sample Sentence Transformer model for encoding\n",
                "from vectorhub.encoders.text.sentence_transformers import SentenceTransformer2Vec\n\nmodel = SentenceTransformer2Vec(\"all-mpnet-base-v2\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "XmkA64yvjOQc"
            },
            "source": [
                "### Encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "I_pAbbaO8F9r"
            },
            "outputs": [],
            "source": [
                "# Encode a single input\nmodel.encode(\"I love working with vectors.\")\n",
                "\n",
                "# documents are saved as a list of dictionaries\ndocuments = [{'sentence': '\"This is the first sentence.\"', '_id': 1}, {'sentence': '\"This is the second sentence.\"', '_id': 2}]\n\n# Encode the `\"sentence\"` field in a list of documents\nencoded_documents = model.encode_documents([\"sentence\"], documents)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "ByFFupgajjmR"
            },
            "source": [
                "### Encoding an entire dataset\n",
                "\n",
                "\n",
                "The easiest way to update an existing dataset with encoding results is to run `encode_documents`. This function fetches all the data-points in a dataset, runs the specified function (i.e. encoding in this case) and writes the result back to the dataset.\n",
                "\n",
                "For instance, in the sample code below, we use a dataset called `ecommerce_dataset`, and encodes the `product_description` field using the `USE2Vec` encoder.\n",
                "You can see the list of the available list of models for vectorising here using [Vectorhub](https://github.com/RelevanceAI/vectorhub) or feel free to bring your own model(s)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "hztjQZUS5Hra"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\nfrom relevanceai.utils.datasets import get_ecommerce_dataset_clean\n\n# Retrieve our sample dataset. - This comes in the form of a list of documents.\ndocuments = get_ecommerce_dataset_clean()\n\npd.DataFrame.from_dict(documents).head()\nds = client.Dataset('quickstart_example_encoding')\nds.insert_documents(documents)\n",
                "\n",
                "ds[\"product_title\"].apply(lambda x: model.encode(x), output_field=\"product_title_vector_\")\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "name": "RelevanceAI-ReadMe-How-To-Vectorize.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}