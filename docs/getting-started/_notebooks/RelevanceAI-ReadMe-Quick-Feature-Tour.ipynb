{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<img src=\"https://raw.githubusercontent.com/RelevanceAI/RelevanceAI-readme-docs/v2.0.0/docs_template/_assets/RelevanceAI-logo.svg\" width=\"300\" alt=\"Relevance AI\" />\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/RelevanceAI-readme-docs/blob/v1.4.5/docs/getting-started/_notebooks/RelevanceAI-ReadMe-Quick-Feature-Tour.ipynb)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Y6cViLnHTdIx"
            },
            "source": [
                "### 1. Set up Relevance AI\n",
                "\n",
                "Get started using our RelevanceAI SDK and use of [Vectorhub](https://hub.getvectorai.com/)'s [CLIP model](https://hub.getvectorai.com/model/text_image%2Fclip) for encoding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "QT2fS1S8TeEr"
            },
            "outputs": [],
            "source": [
                "# remove `!` if running the line in a terminal\n!pip install -U RelevanceAI[notebook]==1.4.5\n# remove `!` if running the line in a terminal\n!pip install -U vectorhub[clip]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "RGK78n-MYVr_"
            },
            "source": [
                "Follow the signup flow and get your credentials below otherwise, you can sign up/login and find your credentials in the settings [here](https://auth.relevance.ai/signup/?callback=https%3A%2F%2Fcloud.relevance.ai%2Flogin%3Fredirect%3Dcli-api)\n",
                "\n",
                "![](https://drive.google.com/uc?id=131M2Kpz5s9GmhNRnqz6b0l0Pw9DHVRWs)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "0rFqSnr4hkKA"
            },
            "outputs": [],
            "source": [
                "\n",
                "from relevanceai import Client\n\n\"\"\"\nYou can sign up/login and find your credentials here: https://cloud.relevance.ai/sdk/api\nOnce you have signed up, click on the value under `Activation token` and paste it here\n\"\"\"\nclient = Client()\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "XvhHebojYGqi"
            },
            "source": [
                "![](https://drive.google.com/uc?id=1owtvwZKTTcrOHBlgKTjqiMOvrN3DGrF6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "KG9EmjmVT6D6"
            },
            "source": [
                "### 2. Create a dataset and insert data\n",
                "\n",
                "Use one of our sample datasets to upload into your own project!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "9H-205hr1zdw"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\nfrom relevanceai.datasets import get_ecommerce_dataset_clean\n\n# Retrieve our sample dataset. - This comes in the form of a list of documents.\ndocuments = get_ecommerce_dataset_clean()\n\npd.DataFrame.from_dict(documents).head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "bw_dMhGvT6l4"
            },
            "outputs": [],
            "source": [
                "\n",
                "ds = client.Dataset(\"quickstart\")\nds.insert_documents(documents)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "98oWbcr0X7tt"
            },
            "source": [
                "See your dataset in the dashboard\n",
                "\n",
                "\n",
                "![](https://drive.google.com/uc?id=1nloY4S8R1B8GY2_QWkb0BGY3bLrG-8D-)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "XrPNeOHePH-C"
            },
            "source": [
                "\n",
                "### 3. Encode data and upload vectors into your new dataset\n",
                "\n",
                "Encode a new product image vector using [Vectorhub's](https://hub.getvectorai.com/) `Clip2Vec` models and update your dataset with the resulting vectors. Please refer to [Vectorhub](https://github.com/RelevanceAI/vectorhub) for more details.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "0MHfR8nLPC40"
            },
            "outputs": [],
            "source": [
                "from vectorhub.bi_encoders.text_image.torch import Clip2Vec\n\nmodel = Clip2Vec()\n\n# Set the default encode to encoding an image\nmodel.encode = model.encode_image\ndocuments = model.encode_documents(fields=['product_image'], documents=documents)\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "-bXlPMBjeAIy"
            },
            "outputs": [],
            "source": [
                "ds.upsert_documents(documents=documents)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "rbyo2WHvc3mg"
            },
            "outputs": [],
            "source": [
                "ds.schema\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "5ua_ImlNZluZ"
            },
            "source": [
                "\n",
                "Monitor your vectors in the dashboard\n",
                "\n",
                "\n",
                "![](https://drive.google.com/uc?id=1d2jhjhwvPucfebUphIiqGVmR1Td2uYzM)\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "izq6fywPmwuG"
            },
            "source": [
                "### 4. Run clustering on your vectors\n",
                "\n",
                "Run clustering on your vectors to better understand your data! \n",
                "\n",
                "You can view your clusters in our clustering dashboard following the link which is provided after the clustering is finished! \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "VIMERP4um8iX"
            },
            "outputs": [],
            "source": [
                "\n",
                "clusterer = ds.auto_cluster(\"kmeans-10\", [\"product_image_clip_vector_\"])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "yVSKKeBxabBS"
            },
            "source": [
                "You can see the new `_cluster_` field that is added to your document schema. \n",
                "Clustering results are uploaded back to the dataset as an additional field.\n",
                "The default `alias` of the cluster will be the `kmeans_<k>`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "GAVr-QyMo00U"
            },
            "outputs": [],
            "source": [
                "ds.schema\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Ai8f_pqz1Nwk"
            },
            "outputs": [],
            "source": [
                "clusterer.list_closest_to_center()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "c1cd4x8GubIi"
            },
            "source": [
                "See your cluster centers in the dashboard\n",
                "\n",
                "\n",
                "![](https://drive.google.com/uc?id=1P0ZJcTd-Kl7TUwzFHEe3JuJpf_cTTP6J)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "sQO0Sv58T8IP"
            },
            "source": [
                "### 4. Run a vector search\n",
                "\n",
                "Encode your query and find your image results!\n",
                "\n",
                "Here our query is just a simple vector query, but our search comes with out of the box support for features such as multi-vector, filters, facets and traditional keyword matching to combine with your vector search. You can read more about how to construct a multivector query with those features [here](https://docs.relevance.ai/docs/vector-search-prerequisites).\n",
                "\n",
                "See your search results on the dashboard here https://cloud.relevance.ai/sdk/search.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "zLFesEtgT8dV"
            },
            "outputs": [],
            "source": [
                "\n",
                "query = \"gifts for the holidays\"\nquery_vector = model.encode(query)\nmultivector_query=[\n    { \"vector\": query_vector, \"fields\": [\"product_image_clip_vector_\"]}\n]\nresults = ds.vector_search(\n    multivector_query=multivector_query,\n    page_size=10\n)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "oksG2wlx9hFq"
            },
            "source": [
                "See your multi-vector search results in the dashboard\n",
                "\n",
                "![](https://drive.google.com/uc?id=1qpc7oK0uxj2IRm4a9giO5DBey8sm8GP8)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "HvozIFIMUyKM"
            },
            "source": [
                "\n",
                "\n",
                "Want to quickly create some example applications with Relevance AI? Check out some other guides below!\n",
                "- [Text-to-image search with OpenAI's CLIP](https://docs.relevance.ai/docs/quickstart-text-to-image-search)\n",
                "- [Hybrid Text search with Universal Sentence Encoder using Vectorhub](https://docs.relevance.ai/docs/quickstart-text-search)\n",
                "- [Text search with Universal Sentence Encoder Question Answer from Google](https://docs.relevance.ai/docs/quickstart-question-answering)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "eweubscO81bP"
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "RelevanceAI-ReadMe-Quick-Feature-Tour.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}