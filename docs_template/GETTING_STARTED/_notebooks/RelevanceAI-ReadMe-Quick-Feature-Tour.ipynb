{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://relevance.ai/wp-content/uploads/2021/11/logo.79f303e-1.svg\" width=\"300\" alt=\"Relevance AI\" />\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RelevanceAI/RelevanceAI-readme-docs/blob/v0.33.2/docs/GETTING_STARTED/_notebooks/RelevanceAI-ReadMe-Quick-Feature-Tour.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6cViLnHTdIx"
      },
      "source": [
        "### 1. Set up Relevance AI\n",
        "\n",
        "Get started using our RelevanceAI SDK and use of [Vectorhub](https://hub.getvectorai.com/)'s [CLIP model](https://hub.getvectorai.com/model/text_image%2Fclip) for encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT2fS1S8TeEr"
      },
      "outputs": [],
      "source": [
        "@@@+ relevanceai_installation, RELEVANCEAI_SDK_VERSION=RELEVANCEAI_SDK_VERSION; vectorhub_clip_installation @@@"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGK78n-MYVr_"
      },
      "source": [
        "Follow the signup flow and get your credentials below otherwise, you can sign up/login and find your credentials in the settings [here](https://auth.relevance.ai/signup/?callback=https%3A%2F%2Fcloud.relevance.ai%2Flogin%3Fredirect%3Dcli-api)\n",
        "\n",
        "![](https://drive.google.com/uc?id=131M2Kpz5s9GmhNRnqz6b0l0Pw9DHVRWs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rFqSnr4hkKA"
      },
      "outputs": [],
      "source": [
        "\n",
        "@@@ client_instantiation @@@\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvhHebojYGqi"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1owtvwZKTTcrOHBlgKTjqiMOvrN3DGrF6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG9EmjmVT6D6"
      },
      "source": [
        "### 2. Create a dataset and insert data\n",
        "\n",
        "Use one of our sample datasets to upload into your own project!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H-205hr1zdw"
      },
      "outputs": [],
      "source": [
        "@@@ get_ecommerce_dataset_clean @@@"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw_dMhGvT6l4"
      },
      "outputs": [],
      "source": [
        "\n",
        "@@@ dataset_basics, DATASET_ID=QUICKSTART_DATASET_ID @@@"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98oWbcr0X7tt"
      },
      "source": [
        "See your dataset in the dashboard\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?id=1nloY4S8R1B8GY2_QWkb0BGY3bLrG-8D-)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPNeOHePH-C"
      },
      "source": [
        "\n",
        "### 3. Encode data and upload vectors into your new dataset\n",
        "\n",
        "Encode a new product image vector using [Vectorhub's](https://hub.getvectorai.com/) `Clip2Vec` models and update your dataset with the resulting vectors. Please refer to [Vectorhub](https://github.com/RelevanceAI/vectorhub) for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MHfR8nLPC40"
      },
      "outputs": [],
      "source": [
        "@@@ clip2vec_encode_image_documents, IMAGE_VECTOR_FIELDS=['product_image'] @@@"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bXlPMBjeAIy"
      },
      "outputs": [],
      "source": [
        "@@@ upsert_documents @@@\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbyo2WHvc3mg"
      },
      "outputs": [],
      "source": [
        "@@@ dataset_schema @@@\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ua_ImlNZluZ"
      },
      "source": [
        "\n",
        "Monitor your vectors in the dashboard\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?id=1d2jhjhwvPucfebUphIiqGVmR1Td2uYzM)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izq6fywPmwuG"
      },
      "source": [
        "### 4. Run clustering on your vectors\n",
        "\n",
        "Run clustering on your vectors to better understand your data! \n",
        "\n",
        "You can view your clusters in our clustering dashboard following the link which is provided after the clustering is finished! \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIMERP4um8iX"
      },
      "outputs": [],
      "source": [
        "\n",
        "@@@ auto_cluster, KMEANS=KMEANS-10, VECTOR_FIELD=IMAGE_CLIP_VEC @@@\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVSKKeBxabBS"
      },
      "source": [
        "You can see the new `_cluster_` field that is added to your document schema. \n",
        "Clustering results are uploaded back to the dataset as an additional field.\n",
        "The default `alias` of the cluster will be the `kmeans_<k>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAVr-QyMo00U"
      },
      "outputs": [],
      "source": [
        "@@@ dataset_schema @@@"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai8f_pqz1Nwk"
      },
      "outputs": [],
      "source": [
        "@@@ list_closest @@@"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1cd4x8GubIi"
      },
      "source": [
        "See your cluster centers in the dashboard\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?id=1P0ZJcTd-Kl7TUwzFHEe3JuJpf_cTTP6J)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQO0Sv58T8IP"
      },
      "source": [
        "### 4. Run a vector search\n",
        "\n",
        "Encode your query and find your image results!\n",
        "\n",
        "Here our query is just a simple vector query, but our search comes with out of the box support for features such as multi-vector, filters, facets and traditional keyword matching to combine with your vector search. You can read more about how to construct a multivector query with those features [here](https://docs.relevance.ai/docs/vector-search-prerequisites).\n",
        "\n",
        "See your search results on the dashboard here https://cloud.relevance.ai/sdk/search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLFesEtgT8dV"
      },
      "outputs": [],
      "source": [
        "\n",
        "@@@+ encode_text_query, QUERY=\"xmas gifts\"; vector_search, MULTIVECTOR_QUERY=FEATURE_TOUR_MULTI_VECTOR_SEARCH_QUERY, PAGE_SIZE=10 @@@"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oksG2wlx9hFq"
      },
      "source": [
        "See your multi-vector search results in the dashboard\n",
        "\n",
        "![](https://drive.google.com/uc?id=1qpc7oK0uxj2IRm4a9giO5DBey8sm8GP8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvozIFIMUyKM"
      },
      "source": [
        "\n",
        "\n",
        "Want to quickly create some example applications with Relevance AI? Check out some other guides below!\n",
        "- [Text-to-image search with OpenAI's CLIP](https://docs.relevance.ai/docs/quickstart-text-to-image-search)\n",
        "- [Hybrid Text search with Universal Sentence Encoder using Vectorhub](https://docs.relevance.ai/docs/quickstart-text-search)\n",
        "- [Text search with Universal Sentence Encoder Question Answer from Google](https://docs.relevance.ai/docs/quickstart-question-answering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eweubscO81bP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RelevanceAI-ReadMe-Quick-Feature-Tour.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
