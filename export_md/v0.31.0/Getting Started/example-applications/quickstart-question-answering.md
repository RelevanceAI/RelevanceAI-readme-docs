---
title: "Question answering (using USE QA Tensorflow Hub)"
slug: "quickstart-question-answering"
excerpt: "Get started with Relevance AI in 5 minutes!"
hidden: false
createdAt: "2021-11-05T06:25:12.543Z"
updatedAt: "2022-01-20T05:05:33.448Z"
---
This quickstart shows how easy it is to get started and how to quickly build question-answering applications using Relevance AI in just a few lines of code. Visit the documentation pages on use-cases for more in-depth tutorials and explanations for experimenting with stronger vector search.
[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/9be653c-download.png",
        "download.png",
        4288,
        1128,
        "#ebedf4"
      ],
      "caption": "Process of this quickstart"
    }
  ]
}
[/block]
For each application, we demonstrate the ease of
* encoding data,
* indexing the data
* vector search

to build powerful applications

**Try it out in Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zL2mwBVCPaccjB7o7XoVJVJKOWRom8mq?usp=sharing)

### What I Need
* Project and API Key: Grab your RelevanceAI project and API key by [signing up](https://cloud.relevance.ai/ )
* Python 3 (ideally a Jupyter Notebook/Colab environment)

### Installation Requirements

Prior to starting, we need to install the main dependencies.
[block:code]
{
  "codes": [
    {
      "code": "# RelevanceAi installation\npip install -U RelevanceAI[notebook]==0.27.0\n\n# Vectorhub installation for quick access to Sentence Transformers\npip install vectorhub[encoders-text-tfhub]",
      "language": "shell",
      "name": "Bash"
    }
  ]
}
[/block]
### Setting Up Client

To be able to use Relevance AI, you need to instantiate a client. This needs a Project and API key that can be accessed at https://cloud.relevance.ai/ in the settings area! Alternatively, you can run the code below and follow the link and the guide.

[block:code]
{
  "codes": [
    {
      "code": "from relevanceai import Client \n\n\"\"\"\nRunning this cell will provide you with \nthe link to sign up/login page where you can find your credentials.\nOnce you have signed up, click on the value under `Authorization token` \nin the API tab\nand paste it in the appreared Auth token box below\n\"\"\"\n\nclient = Client()",
      "language": "python",
      "name": "Python (SDK)"
    }
  ]
}
[/block]
For this guide, we use our sample ecommerce dataset as shown below:
[block:code]
{
  "codes": [
    {
      "code": "import pandas as pd\nfrom relevanceai.datasets import get_ecommerce_dataset\n\n# Retrieve our sample dataset. - This comes in the form of a list of documents.\ndocuments = get_ecommerce_dataset()\n\npd.DataFrame.from_dict(documents).head()",
      "language": "python"
    }
  ]
}
[/block]
## Question Answering (Using TFHub's Universal Sentence Encoder QA)

Question answering can be a useful application of vector databases particularly for customer support and supporting search for FAQ documents. Here, we show an example of using TFHub's Question Answering Model.

### Data prepration
First, we will define our encoder functions:
[block:code]
{
  "codes": [
    {
      "code": "import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport tensorflow_text\n\n# Here we load the model and define how we encode\nmodule = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')\n\n# First we define how we encode the queries\ndef encode_query(query: str):\n    return module.signatures['question_encoder'](tf.constant([query]))['outputs'][0].numpy().tolist()\n\n# We then want to define how we encode the answers\ndef encode_answer(answer: str):\n    return module.signatures['response_encoder'](\n        input=tf.constant([answer]), \n        context=tf.constant([answer]))['outputs'][0].numpy().tolist()\n",
      "language": "python",
      "name": "Python (SDK)"
    }
  ]
}
[/block]
Next, we will encode the `product_title` field within our documents:
[block:code]
{
  "codes": [
    {
      "code": "# Then loop through the encoding as such\nfor d in tqdm(documents):\n    d['product_title_use_qa_vector_'] = encode_answer(d['product_title'])\n",
      "language": "python"
    }
  ]
}
[/block]
Finally, we can upload the results to a dataset called `quickstart_tfhub_qa` in the Relevance AI platform:
[block:code]
{
  "codes": [
    {
      "code": "# Then insert them into the database to get started\nclient.insert_documents(\"quickstart_tfhub_qa\", documents)",
      "language": "python"
    }
  ]
}
[/block]
### Search
To be able to search within vectors that are generated by the Universal Sentence Encoder, we need to encode the query with the same vectorizer and then form a vector search as shown below:
[block:code]
{
  "codes": [
    {
      "code": "query = \"for my baby daughter\"\nquery_vector = encode_query(query)\n\nresults = client.services.search.vector(\n    \"quickstart_tfhub_qa\",\n    multivector_query=[\n        {\n            \"vector\": query_vector,\n            \"fields\": [\"product_title_use_qa_vector_\"]}\n    ],\n    page_size=5\n)",
      "language": "python",
      "name": "Python (SDK)"
    }
  ]
}
[/block]
Results can be seen on the Relevance AI dashboard accessible via the link provided after the search is done, or through Relevance AI json_shower:
[block:code]
{
  "codes": [
    {
      "code": "from relevanceai import show_json\nshow_json(\n    results, text_fields=[\"product_title\"]\n)",
      "language": "python",
      "name": "Python (SDK)"
    }
  ]
}
[/block]

[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/3946e27-Capture.PNG",
        "Capture.PNG",
        630,
        217,
        "#484848"
      ],
      "caption": "Sample of text search results for \"for my baby daughter\""
    }
  ]
}
[/block]

[block:api-header]
{
  "title": "Final Code"
}
[/block]

[block:code]
{
  "codes": [
    {
      "code": "import pandas as pd\nimport uuid\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport tensorflow_text\n\nfrom relevanceai import Client\nfrom relevanceai import show_json\nfrom relevanceai.datasets import get_ecommerce_dataset\n\n\nclient = Client()\n\n# data\n# Retrieve our sample dataset. - This comes in the form of a list of documents.\ndocuments = get_ecommerce_dataset()\n\npd.DataFrame.from_dict(documents).head()\n\n# Here we load the model and define how we encode\nmodule = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')\n\n# First we define how we encode the queries\ndef encode_query(query: str):\n    return module.signatures['question_encoder'](tf.constant([query]))['outputs'][0].numpy().tolist()\n\n# We then want to define how we encode the answers\ndef encode_answer(answer: str):\n    return module.signatures['response_encoder'](\n        input=tf.constant([answer]), \n        context=tf.constant([answer]))['outputs'][0].numpy().tolist()\n\n# Then loop through the encoding as such\nfor d in tqdm(documents):\n    d['product_title_use_qa_vector_'] = encode_answer(d['product_title'])\n\n# adding the id field\nfor d in documents:\n  d['_id'] = uuid.uuid4().__str__()    # Each document must have a field '_id'\n\n# Insert the documents into a dataset called quickstart_tfhub_qa.\nclient.insert_documents(\"quickstart_tfhub_qa\", documents)\n\n# Then insert them into the database to get started\nclient.insert_documents(\"quickstart_tfhub_qa\", documents)\n\nquery = \"for my baby daughter\"\nquery_vector = encode_query(query)\nresults = client.services.search.vector(\n    \"quickstart_tfhub_qa\",\n    multivector_query=[\n        {\n            \"vector\": query_vector,\n            \"fields\": [\"product_title_use_qa_vector_\"]}\n    ],\n    page_size=5\n)\n\n\nshow_json(\n    results, text_fields=[\"product_title\"]\n)",
      "language": "python",
      "name": "Python (SDK)"
    }
  ]
}
[/block]